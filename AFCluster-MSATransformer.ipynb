{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AFCluster -> MSA Transformer Analysis"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup AFCluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Setup AFCluster\n",
        "%%bash\n",
        "if [ ! -d AF_cluster ];then\n",
        "  git clone https://github.com/AkanoLoki/AF_cluster.git\n",
        "fi\n",
        "if [ ! -d output ]; then\n",
        "  mkdir output\n",
        "fi\n",
        "pip -q install ml-collections dm-haiku biopython polyleven"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Cluster MSA\n",
        "keyword = 'test' #@param {type:\"string\"}\n",
        "#@markdown - Specify the output identifier string\n",
        "a3mInput = '/content/test.a3m' #@param {type:\"string\"}\n",
        "#@markdown - Specify the input a3m file\n",
        "outputDir = '/content/subsampled_MSAs' #@param {type:\"string\"}\n",
        "#@markdown - Specify the output directory of clustered MSAs (will mkdir if folder not present)\n",
        "msaTDir = '/content/MSATransformer_output' #@param {type:\"string\"}\n",
        "#@markdown - Specify the output directory of MSA Transformer (will mkdir if folder not present)\n",
        "oligoState = 1 #@param {type:\"integer\"}\n",
        "#@markdown - Specify the oligomeric state of the protein\n",
        "if oligoState < 1:\n",
        "    raise Exception(\"Oligomeric state cannot be smaller than 1\")\n",
        "import os\n",
        "os.system(f\"/content/AF_cluster/scripts/ClusterMSA.py {keyword} -i {a3mInput} -o {outputDir} --n_mer {oligoState}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup ESM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "I2MLDXLJQmnB",
        "outputId": "83c28ce1-1895-410b-bb97-bbb0079d5e52"
      },
      "outputs": [],
      "source": [
        "#@title Setup ESM dependencies\n",
        "%pip -q install biotite\n",
        "%pip -q install git+https://github.com/facebookresearch/esm.git\n",
        "!apt-get install aria2\n",
        "!mkdir -p /root/.cache/torch/hub/checkpoints\n",
        "!aria2c --dir=/root/.cache/torch/hub/checkpoints --continue --split 8 --max-connection-per-server 8 https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t33_650M_UR50S.pt\n",
        "!aria2c --dir=/root/.cache/torch/hub/checkpoints --continue --split 8 --max-connection-per-server 8 https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t33_650M_UR50S-contact-regression.pt\n",
        "!aria2c --dir=/root/.cache/torch/hub/checkpoints --continue --split 8 --max-connection-per-server 8 https://dl.fbaipublicfiles.com/fair-esm/models/esm_msa1b_t12_100M_UR50S.pt\n",
        "!aria2c --dir=/root/.cache/torch/hub/checkpoints --continue --split 8 --max-connection-per-server 8 https://dl.fbaipublicfiles.com/fair-esm/regression/esm_msa1b_t12_100M_UR50S-contact-regression.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Invoke HWS ESM Script\n",
        "os.system(f\"/content/AF_cluster/scripts/runESM.py {outputDir}*a3m -o {msaTDir} â€”model msa_t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fQ8ztOjvQbJV",
        "outputId": "ca29c221-dc07-4310-dac7-a8554d64ab2b"
      },
      "outputs": [],
      "source": [
        "#@title Setup ESM python imports\n",
        "from typing import List, Tuple, Optional, Dict, NamedTuple, Union, Callable\n",
        "import itertools\n",
        "import os\n",
        "import string\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from scipy.spatial.distance import squareform, pdist, cdist\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from Bio import SeqIO\n",
        "import biotite.structure as bs\n",
        "from biotite.structure.io.pdbx import PDBxFile, get_structure\n",
        "from biotite.database import rcsb\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "import esm\n",
        "\n",
        "torch.set_grad_enabled(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Lpt-Ijz2T6zF"
      },
      "outputs": [],
      "source": [
        "#@title Setup ESM functions\n",
        "# This is an efficient way to delete lowercase characters and insertion characters from a string\n",
        "deletekeys = dict.fromkeys(string.ascii_lowercase)\n",
        "deletekeys[\".\"] = None\n",
        "deletekeys[\"*\"] = None\n",
        "translation = str.maketrans(deletekeys)\n",
        "\n",
        "def read_sequence(filename: str) -> Tuple[str, str]:\n",
        "    \"\"\" Reads the first (reference) sequences from a fasta or MSA file.\"\"\"\n",
        "    record = next(SeqIO.parse(filename, \"fasta\"))\n",
        "    return record.description, str(record.seq)\n",
        "\n",
        "def remove_insertions(sequence: str) -> str:\n",
        "    \"\"\" Removes any insertions into the sequence. Needed to load aligned sequences in an MSA. \"\"\"\n",
        "    return sequence.translate(translation)\n",
        "\n",
        "def read_msa(filename: str) -> List[Tuple[str, str]]:\n",
        "    \"\"\" Reads the sequences from an MSA file, automatically removes insertions.\"\"\"\n",
        "    return [(record.description, remove_insertions(str(record.seq))) for record in SeqIO.parse(filename, \"fasta\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "n4FBkOUaWuXb"
      },
      "outputs": [],
      "source": [
        "def extend(a, b, c, L, A, D):\n",
        "    \"\"\"\n",
        "    input:  3 coords (a,b,c), (L)ength, (A)ngle, and (D)ihedral\n",
        "    output: 4th coord\n",
        "    \"\"\"\n",
        "\n",
        "    def normalize(x):\n",
        "        return x / np.linalg.norm(x, ord=2, axis=-1, keepdims=True)\n",
        "\n",
        "    bc = normalize(b - c)\n",
        "    n = normalize(np.cross(b - a, bc))\n",
        "    m = [bc, np.cross(n, bc), n]\n",
        "    d = [L * np.cos(A), L * np.sin(A) * np.cos(D), -L * np.sin(A) * np.sin(D)]\n",
        "    return c + sum([m * d for m, d in zip(m, d)])\n",
        "\n",
        "\n",
        "def contacts_from_pdb(\n",
        "    structure: bs.AtomArray,\n",
        "    distance_threshold: float = 8.0,\n",
        "    chain: Optional[str] = None,\n",
        ") -> np.ndarray:\n",
        "    mask = ~structure.hetero\n",
        "    if chain is not None:\n",
        "        mask &= structure.chain_id == chain\n",
        "\n",
        "    N = structure.coord[mask & (structure.atom_name == \"N\")]\n",
        "    CA = structure.coord[mask & (structure.atom_name == \"CA\")]\n",
        "    C = structure.coord[mask & (structure.atom_name == \"C\")]\n",
        "\n",
        "    Cbeta = extend(C, N, CA, 1.522, 1.927, -2.143)\n",
        "    dist = squareform(pdist(Cbeta))\n",
        "\n",
        "    contacts = dist < distance_threshold\n",
        "    contacts = contacts.astype(np.int64)\n",
        "    contacts[np.isnan(dist)] = -1\n",
        "    return contacts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dSdxag5OmOmK"
      },
      "outputs": [],
      "source": [
        "# Select sequences from the MSA to maximize the hamming distance\n",
        "# Alternatively, can use hhfilter\n",
        "def greedy_select(msa: List[Tuple[str, str]], num_seqs: int, mode: str = \"max\") -> List[Tuple[str, str]]:\n",
        "    assert mode in (\"max\", \"min\")\n",
        "    if len(msa) <= num_seqs:\n",
        "        return msa\n",
        "\n",
        "    array = np.array([list(seq) for _, seq in msa], dtype=np.bytes_).view(np.uint8)\n",
        "\n",
        "    optfunc = np.argmax if mode == \"max\" else np.argmin\n",
        "    all_indices = np.arange(len(msa))\n",
        "    indices = [0]\n",
        "    pairwise_distances = np.zeros((0, len(msa)))\n",
        "    for _ in range(num_seqs - 1):\n",
        "        dist = cdist(array[indices[-1:]], array, \"hamming\")\n",
        "        pairwise_distances = np.concatenate([pairwise_distances, dist])\n",
        "        shifted_distance = np.delete(pairwise_distances, indices, axis=1).mean(0)\n",
        "        shifted_index = optfunc(shifted_distance)\n",
        "        index = np.delete(all_indices, indices)[shifted_index]\n",
        "        indices.append(index)\n",
        "    indices = sorted(indices)\n",
        "    return [msa[idx] for idx in indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "c7T9xWTXeIaR"
      },
      "outputs": [],
      "source": [
        "def compute_precisions(\n",
        "    predictions: torch.Tensor,\n",
        "    targets: torch.Tensor,\n",
        "    src_lengths: Optional[torch.Tensor] = None,\n",
        "    minsep: int = 6,\n",
        "    maxsep: Optional[int] = None,\n",
        "    override_length: Optional[int] = None,  # for casp\n",
        "):\n",
        "    if isinstance(predictions, np.ndarray):\n",
        "        predictions = torch.from_numpy(predictions)\n",
        "    if isinstance(targets, np.ndarray):\n",
        "        targets = torch.from_numpy(targets)\n",
        "    if predictions.dim() == 2:\n",
        "        predictions = predictions.unsqueeze(0)\n",
        "    if targets.dim() == 2:\n",
        "        targets = targets.unsqueeze(0)\n",
        "    override_length = (targets[0, 0] >= 0).sum()\n",
        "\n",
        "    # Check sizes\n",
        "    if predictions.size() != targets.size():\n",
        "        raise ValueError(\n",
        "            f\"Size mismatch. Received predictions of size {predictions.size()}, \"\n",
        "            f\"targets of size {targets.size()}\"\n",
        "        )\n",
        "    device = predictions.device\n",
        "\n",
        "    batch_size, seqlen, _ = predictions.size()\n",
        "    seqlen_range = torch.arange(seqlen, device=device)\n",
        "\n",
        "    sep = seqlen_range.unsqueeze(0) - seqlen_range.unsqueeze(1)\n",
        "    sep = sep.unsqueeze(0)\n",
        "    valid_mask = sep >= minsep\n",
        "    valid_mask = valid_mask & (targets >= 0)  # negative targets are invalid\n",
        "\n",
        "    if maxsep is not None:\n",
        "        valid_mask &= sep < maxsep\n",
        "\n",
        "    if src_lengths is not None:\n",
        "        valid = seqlen_range.unsqueeze(0) < src_lengths.unsqueeze(1)\n",
        "        valid_mask &= valid.unsqueeze(1) & valid.unsqueeze(2)\n",
        "    else:\n",
        "        src_lengths = torch.full([batch_size], seqlen, device=device, dtype=torch.long)\n",
        "\n",
        "    predictions = predictions.masked_fill(~valid_mask, float(\"-inf\"))\n",
        "\n",
        "    x_ind, y_ind = np.triu_indices(seqlen, minsep)\n",
        "    predictions_upper = predictions[:, x_ind, y_ind]\n",
        "    targets_upper = targets[:, x_ind, y_ind]\n",
        "\n",
        "    topk = seqlen if override_length is None else max(seqlen, override_length)\n",
        "    indices = predictions_upper.argsort(dim=-1, descending=True)[:, :topk]\n",
        "    topk_targets = targets_upper[torch.arange(batch_size).unsqueeze(1), indices]\n",
        "    if topk_targets.size(1) < topk:\n",
        "        topk_targets = F.pad(topk_targets, [0, topk - topk_targets.size(1)])\n",
        "\n",
        "    cumulative_dist = topk_targets.type_as(predictions).cumsum(-1)\n",
        "\n",
        "    gather_lengths = src_lengths.unsqueeze(1)\n",
        "    if override_length is not None:\n",
        "        gather_lengths = override_length * torch.ones_like(\n",
        "            gather_lengths, device=device\n",
        "        )\n",
        "\n",
        "    gather_indices = (\n",
        "        torch.arange(0.1, 1.1, 0.1, device=device).unsqueeze(0) * gather_lengths\n",
        "    ).type(torch.long) - 1\n",
        "\n",
        "    binned_cumulative_dist = cumulative_dist.gather(1, gather_indices)\n",
        "    binned_precisions = binned_cumulative_dist / (gather_indices + 1).type_as(\n",
        "        binned_cumulative_dist\n",
        "    )\n",
        "\n",
        "    pl5 = binned_precisions[:, 1]\n",
        "    pl2 = binned_precisions[:, 4]\n",
        "    pl = binned_precisions[:, 9]\n",
        "    auc = binned_precisions.mean(-1)\n",
        "\n",
        "    return {\"AUC\": auc, \"P@L\": pl, \"P@L2\": pl2, \"P@L5\": pl5}\n",
        "\n",
        "\n",
        "def evaluate_prediction(\n",
        "    predictions: torch.Tensor,\n",
        "    targets: torch.Tensor,\n",
        ") -> Dict[str, float]:\n",
        "    if isinstance(targets, np.ndarray):\n",
        "        targets = torch.from_numpy(targets)\n",
        "    contact_ranges = [\n",
        "        (\"local\", 3, 6),\n",
        "        (\"short\", 6, 12),\n",
        "        (\"medium\", 12, 24),\n",
        "        (\"long\", 24, None),\n",
        "    ]\n",
        "    metrics = {}\n",
        "    targets = targets.to(predictions.device)\n",
        "    for name, minsep, maxsep in contact_ranges:\n",
        "        rangemetrics = compute_precisions(\n",
        "            predictions,\n",
        "            targets,\n",
        "            minsep=minsep,\n",
        "            maxsep=maxsep,\n",
        "        )\n",
        "        for key, val in rangemetrics.items():\n",
        "            metrics[f\"{name}_{key}\"] = val.item()\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "pG3gTskUfyfy"
      },
      "outputs": [],
      "source": [
        "\"\"\"Adapted from: https://github.com/rmrao/evo/blob/main/evo/visualize.py\"\"\"\n",
        "def plot_contacts_and_predictions(\n",
        "    predictions: Union[torch.Tensor, np.ndarray],\n",
        "    contacts: Union[torch.Tensor, np.ndarray],\n",
        "    ax: Optional[mpl.axes.Axes] = None,\n",
        "    # artists: Optional[ContactAndPredictionArtists] = None,\n",
        "    cmap: str = \"Blues\",\n",
        "    ms: float = 1,\n",
        "    title: Union[bool, str, Callable[[float], str]] = True,\n",
        "    animated: bool = False,\n",
        ") -> None:\n",
        "\n",
        "    if isinstance(predictions, torch.Tensor):\n",
        "        predictions = predictions.detach().cpu().numpy()\n",
        "    if isinstance(contacts, torch.Tensor):\n",
        "        contacts = contacts.detach().cpu().numpy()\n",
        "    if ax is None:\n",
        "        ax = plt.gca()\n",
        "\n",
        "    seqlen = contacts.shape[0]\n",
        "    relative_distance = np.add.outer(-np.arange(seqlen), np.arange(seqlen))\n",
        "    bottom_mask = relative_distance < 0\n",
        "    masked_image = np.ma.masked_where(bottom_mask, predictions)\n",
        "    invalid_mask = np.abs(np.add.outer(np.arange(seqlen), -np.arange(seqlen))) < 6\n",
        "    predictions = predictions.copy()\n",
        "    predictions[invalid_mask] = float(\"-inf\")\n",
        "\n",
        "    topl_val = np.sort(predictions.reshape(-1))[-seqlen]\n",
        "    pred_contacts = predictions >= topl_val\n",
        "    true_positives = contacts & pred_contacts & ~bottom_mask\n",
        "    false_positives = ~contacts & pred_contacts & ~bottom_mask\n",
        "    other_contacts = contacts & ~pred_contacts & ~bottom_mask\n",
        "\n",
        "    if isinstance(title, str):\n",
        "        title_text: Optional[str] = title\n",
        "    elif title:\n",
        "        long_range_pl = compute_precisions(predictions, contacts, minsep=24)[\n",
        "            \"P@L\"\n",
        "        ].item()\n",
        "        if callable(title):\n",
        "            title_text = title(long_range_pl)\n",
        "        else:\n",
        "            title_text = f\"Long Range P@L: {100 * long_range_pl:0.1f}\"\n",
        "    else:\n",
        "        title_text = None\n",
        "\n",
        "    img = ax.imshow(masked_image, cmap=cmap, animated=animated)\n",
        "    oc = ax.plot(*np.where(other_contacts), \"o\", c=\"grey\", ms=ms)[0]\n",
        "    fn = ax.plot(*np.where(false_positives), \"o\", c=\"r\", ms=ms)[0]\n",
        "    tp = ax.plot(*np.where(true_positives), \"o\", c=\"b\", ms=ms)[0]\n",
        "    ti = ax.set_title(title_text) if title_text is not None else None\n",
        "    # artists = ContactAndPredictionArtists(img, oc, fn, tp, ti)\n",
        "\n",
        "    ax.axis(\"square\")\n",
        "    ax.set_xlim([0, seqlen])\n",
        "    ax.set_ylim([0, seqlen])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Read Data\n",
        "# This is where the data is actually read in\n",
        "PDB_IDS = [\"1j9o\", \"2jp1\"]\n",
        "\n",
        "structures = {\n",
        "    name.lower(): get_structure(PDBxFile.read(rcsb.fetch(name, \"cif\")))[0]\n",
        "    for name in PDB_IDS\n",
        "}\n",
        "\n",
        "contacts = {\n",
        "    name: contacts_from_pdb(structure, chain=\"A\")\n",
        "    for name, structure in structures.items()\n",
        "}\n",
        "\n",
        "msas = {\n",
        "    name: read_msa(f\"data/{name.lower()}_1_A.a3m\")\n",
        "    for name in PDB_IDS\n",
        "}\n",
        "\n",
        "sequences = {\n",
        "    name: msa[0] for name, msa in msas.items()\n",
        "}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6T7Pcz-poDFn"
      },
      "source": [
        "### Predict and Visualize via ESM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Qce87TjvbEDA",
        "outputId": "ed61a404-a59c-417e-b087-77d69a1e168c"
      },
      "outputs": [],
      "source": [
        "#@title ESM-2 pred\n",
        "esm2, esm2_alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
        "esm2 = esm2.eval().cuda()\n",
        "esm2_batch_converter = esm2_alphabet.get_batch_converter()\n",
        "esm2_predictions = {}\n",
        "esm2_results = []\n",
        "for name, inputs in sequences.items():\n",
        "    esm2_batch_labels, esm2_batch_strs, esm2_batch_tokens = esm2_batch_converter([inputs])\n",
        "    esm2_batch_tokens = esm2_batch_tokens.to(next(esm2.parameters()).device)\n",
        "    esm2_predictions[name] = esm2.predict_contacts(esm2_batch_tokens)[0].cpu()\n",
        "    metrics = {\"id\": name, \"model\": \"ESM-2 (Unsupervised)\"}\n",
        "    metrics.update(evaluate_prediction(esm2_predictions[name], contacts[name]))\n",
        "    esm2_results.append(metrics)\n",
        "esm2_results = pd.DataFrame(esm2_results)\n",
        "display(esm2_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "WnlwYZeUbgLO",
        "outputId": "3d3eb320-f12c-46c4-d5c5-4e6467408b54"
      },
      "outputs": [],
      "source": [
        "#@title ESM-2 Graph\n",
        "fig, axes = plt.subplots(figsize=(18, 6), ncols=len(PDB_IDS))\n",
        "for ax, name in zip(axes, PDB_IDS):\n",
        "    prediction = esm2_predictions[name]\n",
        "    target = contacts[name]\n",
        "    plot_contacts_and_predictions(\n",
        "        prediction, target, ax=ax, title = lambda prec: f\"{name}: Long Range P@L: {100 * prec:0.1f}\"\n",
        "    )\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IohE_rsToQAK"
      },
      "source": [
        "### Predict and Visualize via MSA Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "kIiH7a5olI_A"
      },
      "outputs": [],
      "source": [
        "#@title MSA Transformer pred\n",
        "msa_transformer, msa_transformer_alphabet = esm.pretrained.esm_msa1b_t12_100M_UR50S()\n",
        "msa_transformer = msa_transformer.eval().cuda()\n",
        "msa_transformer_batch_converter = msa_transformer_alphabet.get_batch_converter()\n",
        "msa_transformer_predictions = {}\n",
        "msa_transformer_results = []\n",
        "for name, inputs in msas.items():\n",
        "    inputs = greedy_select(inputs, num_seqs=128) # can change this to pass more/fewer sequences\n",
        "    msa_transformer_batch_labels, msa_transformer_batch_strs, msa_transformer_batch_tokens = msa_transformer_batch_converter([inputs])\n",
        "    msa_transformer_batch_tokens = msa_transformer_batch_tokens.to(next(msa_transformer.parameters()).device)\n",
        "    msa_transformer_predictions[name] = msa_transformer.predict_contacts(msa_transformer_batch_tokens)[0].cpu()\n",
        "    metrics = {\"id\": name, \"model\": \"MSA Transformer (Unsupervised)\"}\n",
        "    metrics.update(evaluate_prediction(msa_transformer_predictions[name], contacts[name]))\n",
        "    msa_transformer_results.append(metrics)\n",
        "msa_transformer_results = pd.DataFrame(msa_transformer_results)\n",
        "display(msa_transformer_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "6iPBer65nPRI",
        "outputId": "27ae06e6-153c-4010-9e78-04ce46bbbee7"
      },
      "outputs": [],
      "source": [
        "#@title MSA Transformer Graph\n",
        "fig, axes = plt.subplots(figsize=(18, 6), ncols=len(PDB_IDS))\n",
        "for ax, name in zip(axes, PDB_IDS):\n",
        "    prediction = msa_transformer_predictions[name]\n",
        "    target = contacts[name]\n",
        "    plot_contacts_and_predictions(\n",
        "        prediction, target, ax=ax, title = lambda prec: f\"{name}: Long Range P@L: {100 * prec:0.1f}\"\n",
        "    )\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "U0ukYqqzateL",
        "q1eZWXv1bxGl",
        "i7iXPaDKZ5vx",
        "rb4cDoG2ns91",
        "tV3WCbn6aXL7",
        "mqwybh2Tn_Ou",
        "lW5thQpSn0Rp",
        "cvYiSUg7n5rP",
        "WnZSlf1EoGys"
      ],
      "name": "esm_contact_prediction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

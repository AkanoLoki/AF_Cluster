{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AFCluster -> MSA Transformer Analysis"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup AFCluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Setup AFCluster\n",
        "%%bash\n",
        "if [ ! -d AF_cluster ];then\n",
        "  git clone https://github.com/AkanoLoki/AF_cluster.git\n",
        "fi\n",
        "if [ ! -d output ]; then\n",
        "  mkdir output\n",
        "fi\n",
        "pip -q install ml-collections dm-haiku biopython polyleven"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Cluster MSA\n",
        "keyword = 'test' #@param {type:\"string\"}\n",
        "#@markdown - Specify the output identifier string\n",
        "a3mInput = '/content/test.a3m' #@param {type:\"string\"}\n",
        "#@markdown - Specify the input a3m file\n",
        "outputDir = '/content/subsampled_MSAs' #@param {type:\"string\"}\n",
        "#@markdown - Specify the output directory of clustered MSAs (will mkdir if folder not present)\n",
        "msaTDir = '/content/MSATransformer_output' #@param {type:\"string\"}\n",
        "#@markdown - Specify the output directory of MSA Transformer (will mkdir if folder not present)\n",
        "oligoState = 1 #@param {type:\"integer\"}\n",
        "#@markdown - Specify the oligomeric state of the protein\n",
        "if oligoState < 1:\n",
        "    raise Exception(\"Oligomeric state cannot be smaller than 1\")\n",
        "import os\n",
        "os.system(f\"python /content/AF_cluster/scripts/ClusterMSA.py {keyword} -i {a3mInput} -o {outputDir} --n_mer {oligoState}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setup ESM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "I2MLDXLJQmnB",
        "outputId": "83c28ce1-1895-410b-bb97-bbb0079d5e52"
      },
      "outputs": [],
      "source": [
        "#@title Setup ESM dependencies\n",
        "%pip -q install biotite\n",
        "%pip -q install git+https://github.com/facebookresearch/esm.git\n",
        "!apt-get install aria2\n",
        "!mkdir -p /root/.cache/torch/hub/checkpoints\n",
        "!aria2c --dir=/root/.cache/torch/hub/checkpoints --continue --split 8 --max-connection-per-server 8 https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t33_650M_UR50S.pt\n",
        "!aria2c --dir=/root/.cache/torch/hub/checkpoints --continue --split 8 --max-connection-per-server 8 https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t33_650M_UR50S-contact-regression.pt\n",
        "!aria2c --dir=/root/.cache/torch/hub/checkpoints --continue --split 8 --max-connection-per-server 8 https://dl.fbaipublicfiles.com/fair-esm/models/esm_msa1b_t12_100M_UR50S.pt\n",
        "!aria2c --dir=/root/.cache/torch/hub/checkpoints --continue --split 8 --max-connection-per-server 8 https://dl.fbaipublicfiles.com/fair-esm/regression/esm_msa1b_t12_100M_UR50S-contact-regression.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Invoke HWS ESM MSA-T Script\n",
        "os.system(f\"python /content/AF_cluster/scripts/runESM.py {outputDir}/*a3m -o {msaTDir} --model msa_t\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### excerpted from data_sep2022/00_KaiB/KaiB_landscape_figures.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Setup plot dependencies\n",
        "%pylab inline\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set_style('ticks')\n",
        "sns.set_context('paper')\n",
        "\n",
        "import os\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "blue = sns.color_palette('Blues')[-3]\n",
        "red =  sns.color_palette('Reds')[-3]\n",
        "grey= sns.color_palette('Greys')[-3]\n",
        "\n",
        "def jitterbox(**kwargs):\n",
        "    'supply x, y, hue, data'\n",
        "    sns.stripplot(**kwargs, dodge=True, alpha=0.5,zorder=0)\n",
        "    ax = sns.boxplot(**kwargs, dodge=True, fliersize=0, zorder=10, boxprops = dict(facecolor=(0,0,0,0)))\n",
        "\n",
        "    handles, labels = ax.get_legend_handles_labels()\n",
        "    l = plt.legend(handles[0:3], labels[0:3], bbox_to_anchor=(1, 1), frameon=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_json('KaiB_feats_3recycles.json.zip')\n",
        "df['cluster_ind'] = [os.path.basename(x.replace('.pdb','')).split('_')[-1] for x in df['pdb']]\n",
        "\n",
        "def get_type(pdb):\n",
        "    end = pdb.split('_')[-1]\n",
        "    if end=='REF.pdb':\n",
        "        return 'REF'\n",
        "    elif end.startswith('U'):\n",
        "        return end.split('-')[0]\n",
        "    else:\n",
        "        return 'Tree'\n",
        "    \n",
        "df['Type'] = df.apply(lambda row: get_type(row['pdb']), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_msaT(cluster_ind):\n",
        "    return np.loadtxt('msaT_preds/msa_t__2QKEE_%s.npy' % cluster_ind)\n",
        "\n",
        "tree_df = df.loc[df.Type=='Tree']\n",
        "tree_df['msaT_arr'] = tree_df.apply(lambda row: get_msaT(row['cluster_ind']), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "figure(figsize=(9,3))\n",
        "\n",
        "df = df.sort_values('mean_pLDDT')\n",
        "maxx=1.75\n",
        "subplot(1,3,1)\n",
        "\n",
        "tmp = df.loc[df.Type=='Tree']\n",
        "scatter(tmp['rmsd_ref_2QKEE'], tmp['rmsd_ref_5JYTA'], c=tmp['mean_pLDDT'], cmap='rainbow_r',vmin=50,vmax=90)\n",
        "\n",
        "#colorbar(aspect=3.5,label='MSA size',fraction=0.05,orientation='horizontal',ticks=[1e1,1e2,1e3])\n",
        "xlabel('RMSD to Ground state (2QKE)')\n",
        "ylabel('RMSD to Fold-switch state (5JYT)')\n",
        "\n",
        "xlim([0,maxx])\n",
        "ylim([0,maxx])\n",
        "title('Clustered sampling')\n",
        "\n",
        "subplot(1,3,2)\n",
        "\n",
        "tmp = df.loc[df.Type=='U10']\n",
        "scatter(tmp['rmsd_ref_2QKEE'], tmp['rmsd_ref_5JYTA'], c=tmp['mean_pLDDT'], cmap='rainbow_r',vmin=50,vmax=90)\n",
        "\n",
        "title('Uniform sampling, |MSA| = 10')\n",
        "#colorbar(aspect=3.5,label='MSA size',fraction=0.05,orientation='horizontal',ticks=[1e1,1e2,1e3])\n",
        "xlabel('RMSD to Ground state (2QKE)')\n",
        "ylabel('RMSD to Fold-switch state (5JYT)')\n",
        "\n",
        "xlim([0,maxx])\n",
        "ylim([0,maxx])\n",
        "#\n",
        "\n",
        "subplot(1,3,3)\n",
        "\n",
        "tmp = df.loc[df.Type=='U100']\n",
        "scatter(tmp['rmsd_ref_2QKEE'], tmp['rmsd_ref_5JYTA'], c=tmp['mean_pLDDT'], cmap='rainbow_r',vmin=50,vmax=90)\n",
        "title('Uniform sampling, |MSA| = 100')\n",
        "\n",
        "#colorbar(aspect=3.5,label='MSA size',fraction=0.05,orientation='horizontal',ticks=[1e1,1e2,1e3])\n",
        "xlabel('RMSD to Ground state (2QKE)')\n",
        "ylabel('RMSD to Fold-switch state (5JYT)')\n",
        "\n",
        "xlim([0,maxx])\n",
        "ylim([0,maxx])\n",
        "tight_layout()\n",
        "\n",
        "#savefig('kaib_landscape.pdf',bbox_inches='tight')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        " # get representative clusters of first and second state\n",
        "state_1 = df.loc[df['rmsd_ref_5JYTA']<0.3] #[df['mean_pLDDT']>87.5]\n",
        "print(len(state_1))\n",
        "\n",
        "state_2 = df.loc[df['rmsd_ref_2QKEE']<0.3] #[df['mean_pLDDT']>87.5]\n",
        "print(len(state_2))\n",
        "\n",
        "bkgd = df.loc[df['rmsd_ref_2QKEE']>=0.3][df['rmsd_ref_5JYTA']>=0.3]\n",
        "state_1['state'] = 'FS state'\n",
        "state_2['state'] = 'Ground state'\n",
        "bkgd['state'] = 'Other'\n",
        "\n",
        "df_w_states = pd.concat([state_1, state_2, bkgd])\n",
        "\n",
        "figure(figsize=(3,3))\n",
        "\n",
        "jitterbox(x='Type', y='mean_pLDDT', hue='state', data=df_w_states, \n",
        "              order=['U100','U10','Tree'],\n",
        "              hue_order=['Other', 'FS state', 'Ground state'], palette=[grey, red, blue])\n",
        "ylabel('plDDT')\n",
        "ylim([30,100])\n",
        "xticks(range(3), ['Uniform\\n|MSA|=100', 'Uniform\\n|MSA|=10', 'Clustered'])\n",
        "xlabel('')\n",
        "legend([],frameon=False)\n",
        "\n",
        "tight_layout()\n",
        "\n",
        "#savefig('kaib_state_plddts.pdf',bbox_inches='tight')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fQ8ztOjvQbJV",
        "outputId": "ca29c221-dc07-4310-dac7-a8554d64ab2b"
      },
      "outputs": [],
      "source": [
        "#@title Setup ESM python imports\n",
        "from typing import List, Tuple, Optional, Dict, NamedTuple, Union, Callable\n",
        "import itertools\n",
        "import os\n",
        "import string\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from scipy.spatial.distance import squareform, pdist, cdist\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from Bio import SeqIO\n",
        "import biotite.structure as bs\n",
        "from biotite.structure.io.pdbx import PDBxFile, get_structure\n",
        "from biotite.database import rcsb\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "import esm\n",
        "\n",
        "torch.set_grad_enabled(False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Lpt-Ijz2T6zF"
      },
      "outputs": [],
      "source": [
        "#@title Setup ESM functions\n",
        "# This is an efficient way to delete lowercase characters and insertion characters from a string\n",
        "deletekeys = dict.fromkeys(string.ascii_lowercase)\n",
        "deletekeys[\".\"] = None\n",
        "deletekeys[\"*\"] = None\n",
        "translation = str.maketrans(deletekeys)\n",
        "\n",
        "def read_sequence(filename: str) -> Tuple[str, str]:\n",
        "    \"\"\" Reads the first (reference) sequences from a fasta or MSA file.\"\"\"\n",
        "    record = next(SeqIO.parse(filename, \"fasta\"))\n",
        "    return record.description, str(record.seq)\n",
        "\n",
        "def remove_insertions(sequence: str) -> str:\n",
        "    \"\"\" Removes any insertions into the sequence. Needed to load aligned sequences in an MSA. \"\"\"\n",
        "    return sequence.translate(translation)\n",
        "\n",
        "def read_msa(filename: str) -> List[Tuple[str, str]]:\n",
        "    \"\"\" Reads the sequences from an MSA file, automatically removes insertions.\"\"\"\n",
        "    return [(record.description, remove_insertions(str(record.seq))) for record in SeqIO.parse(filename, \"fasta\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "n4FBkOUaWuXb"
      },
      "outputs": [],
      "source": [
        "def extend(a, b, c, L, A, D):\n",
        "    \"\"\"\n",
        "    input:  3 coords (a,b,c), (L)ength, (A)ngle, and (D)ihedral\n",
        "    output: 4th coord\n",
        "    \"\"\"\n",
        "\n",
        "    def normalize(x):\n",
        "        return x / np.linalg.norm(x, ord=2, axis=-1, keepdims=True)\n",
        "\n",
        "    bc = normalize(b - c)\n",
        "    n = normalize(np.cross(b - a, bc))\n",
        "    m = [bc, np.cross(n, bc), n]\n",
        "    d = [L * np.cos(A), L * np.sin(A) * np.cos(D), -L * np.sin(A) * np.sin(D)]\n",
        "    return c + sum([m * d for m, d in zip(m, d)])\n",
        "\n",
        "\n",
        "def contacts_from_pdb(\n",
        "    structure: bs.AtomArray,\n",
        "    distance_threshold: float = 8.0,\n",
        "    chain: Optional[str] = None,\n",
        ") -> np.ndarray:\n",
        "    mask = ~structure.hetero\n",
        "    if chain is not None:\n",
        "        mask &= structure.chain_id == chain\n",
        "\n",
        "    N = structure.coord[mask & (structure.atom_name == \"N\")]\n",
        "    CA = structure.coord[mask & (structure.atom_name == \"CA\")]\n",
        "    C = structure.coord[mask & (structure.atom_name == \"C\")]\n",
        "\n",
        "    Cbeta = extend(C, N, CA, 1.522, 1.927, -2.143)\n",
        "    dist = squareform(pdist(Cbeta))\n",
        "\n",
        "    contacts = dist < distance_threshold\n",
        "    contacts = contacts.astype(np.int64)\n",
        "    contacts[np.isnan(dist)] = -1\n",
        "    return contacts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dSdxag5OmOmK"
      },
      "outputs": [],
      "source": [
        "# Select sequences from the MSA to maximize the hamming distance\n",
        "# Alternatively, can use hhfilter\n",
        "def greedy_select(msa: List[Tuple[str, str]], num_seqs: int, mode: str = \"max\") -> List[Tuple[str, str]]:\n",
        "    assert mode in (\"max\", \"min\")\n",
        "    if len(msa) <= num_seqs:\n",
        "        return msa\n",
        "\n",
        "    array = np.array([list(seq) for _, seq in msa], dtype=np.bytes_).view(np.uint8)\n",
        "\n",
        "    optfunc = np.argmax if mode == \"max\" else np.argmin\n",
        "    all_indices = np.arange(len(msa))\n",
        "    indices = [0]\n",
        "    pairwise_distances = np.zeros((0, len(msa)))\n",
        "    for _ in range(num_seqs - 1):\n",
        "        dist = cdist(array[indices[-1:]], array, \"hamming\")\n",
        "        pairwise_distances = np.concatenate([pairwise_distances, dist])\n",
        "        shifted_distance = np.delete(pairwise_distances, indices, axis=1).mean(0)\n",
        "        shifted_index = optfunc(shifted_distance)\n",
        "        index = np.delete(all_indices, indices)[shifted_index]\n",
        "        indices.append(index)\n",
        "    indices = sorted(indices)\n",
        "    return [msa[idx] for idx in indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "c7T9xWTXeIaR"
      },
      "outputs": [],
      "source": [
        "def compute_precisions(\n",
        "    predictions: torch.Tensor,\n",
        "    targets: torch.Tensor,\n",
        "    src_lengths: Optional[torch.Tensor] = None,\n",
        "    minsep: int = 6,\n",
        "    maxsep: Optional[int] = None,\n",
        "    override_length: Optional[int] = None,  # for casp\n",
        "):\n",
        "    if isinstance(predictions, np.ndarray):\n",
        "        predictions = torch.from_numpy(predictions)\n",
        "    if isinstance(targets, np.ndarray):\n",
        "        targets = torch.from_numpy(targets)\n",
        "    if predictions.dim() == 2:\n",
        "        predictions = predictions.unsqueeze(0)\n",
        "    if targets.dim() == 2:\n",
        "        targets = targets.unsqueeze(0)\n",
        "    override_length = (targets[0, 0] >= 0).sum()\n",
        "\n",
        "    # Check sizes\n",
        "    if predictions.size() != targets.size():\n",
        "        raise ValueError(\n",
        "            f\"Size mismatch. Received predictions of size {predictions.size()}, \"\n",
        "            f\"targets of size {targets.size()}\"\n",
        "        )\n",
        "    device = predictions.device\n",
        "\n",
        "    batch_size, seqlen, _ = predictions.size()\n",
        "    seqlen_range = torch.arange(seqlen, device=device)\n",
        "\n",
        "    sep = seqlen_range.unsqueeze(0) - seqlen_range.unsqueeze(1)\n",
        "    sep = sep.unsqueeze(0)\n",
        "    valid_mask = sep >= minsep\n",
        "    valid_mask = valid_mask & (targets >= 0)  # negative targets are invalid\n",
        "\n",
        "    if maxsep is not None:\n",
        "        valid_mask &= sep < maxsep\n",
        "\n",
        "    if src_lengths is not None:\n",
        "        valid = seqlen_range.unsqueeze(0) < src_lengths.unsqueeze(1)\n",
        "        valid_mask &= valid.unsqueeze(1) & valid.unsqueeze(2)\n",
        "    else:\n",
        "        src_lengths = torch.full([batch_size], seqlen, device=device, dtype=torch.long)\n",
        "\n",
        "    predictions = predictions.masked_fill(~valid_mask, float(\"-inf\"))\n",
        "\n",
        "    x_ind, y_ind = np.triu_indices(seqlen, minsep)\n",
        "    predictions_upper = predictions[:, x_ind, y_ind]\n",
        "    targets_upper = targets[:, x_ind, y_ind]\n",
        "\n",
        "    topk = seqlen if override_length is None else max(seqlen, override_length)\n",
        "    indices = predictions_upper.argsort(dim=-1, descending=True)[:, :topk]\n",
        "    topk_targets = targets_upper[torch.arange(batch_size).unsqueeze(1), indices]\n",
        "    if topk_targets.size(1) < topk:\n",
        "        topk_targets = F.pad(topk_targets, [0, topk - topk_targets.size(1)])\n",
        "\n",
        "    cumulative_dist = topk_targets.type_as(predictions).cumsum(-1)\n",
        "\n",
        "    gather_lengths = src_lengths.unsqueeze(1)\n",
        "    if override_length is not None:\n",
        "        gather_lengths = override_length * torch.ones_like(\n",
        "            gather_lengths, device=device\n",
        "        )\n",
        "\n",
        "    gather_indices = (\n",
        "        torch.arange(0.1, 1.1, 0.1, device=device).unsqueeze(0) * gather_lengths\n",
        "    ).type(torch.long) - 1\n",
        "\n",
        "    binned_cumulative_dist = cumulative_dist.gather(1, gather_indices)\n",
        "    binned_precisions = binned_cumulative_dist / (gather_indices + 1).type_as(\n",
        "        binned_cumulative_dist\n",
        "    )\n",
        "\n",
        "    pl5 = binned_precisions[:, 1]\n",
        "    pl2 = binned_precisions[:, 4]\n",
        "    pl = binned_precisions[:, 9]\n",
        "    auc = binned_precisions.mean(-1)\n",
        "\n",
        "    return {\"AUC\": auc, \"P@L\": pl, \"P@L2\": pl2, \"P@L5\": pl5}\n",
        "\n",
        "\n",
        "def evaluate_prediction(\n",
        "    predictions: torch.Tensor,\n",
        "    targets: torch.Tensor,\n",
        ") -> Dict[str, float]:\n",
        "    if isinstance(targets, np.ndarray):\n",
        "        targets = torch.from_numpy(targets)\n",
        "    contact_ranges = [\n",
        "        (\"local\", 3, 6),\n",
        "        (\"short\", 6, 12),\n",
        "        (\"medium\", 12, 24),\n",
        "        (\"long\", 24, None),\n",
        "    ]\n",
        "    metrics = {}\n",
        "    targets = targets.to(predictions.device)\n",
        "    for name, minsep, maxsep in contact_ranges:\n",
        "        rangemetrics = compute_precisions(\n",
        "            predictions,\n",
        "            targets,\n",
        "            minsep=minsep,\n",
        "            maxsep=maxsep,\n",
        "        )\n",
        "        for key, val in rangemetrics.items():\n",
        "            metrics[f\"{name}_{key}\"] = val.item()\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "pG3gTskUfyfy"
      },
      "outputs": [],
      "source": [
        "\"\"\"Adapted from: https://github.com/rmrao/evo/blob/main/evo/visualize.py\"\"\"\n",
        "def plot_contacts_and_predictions(\n",
        "    predictions: Union[torch.Tensor, np.ndarray],\n",
        "    contacts: Union[torch.Tensor, np.ndarray],\n",
        "    ax: Optional[mpl.axes.Axes] = None,\n",
        "    # artists: Optional[ContactAndPredictionArtists] = None,\n",
        "    cmap: str = \"Blues\",\n",
        "    ms: float = 1,\n",
        "    title: Union[bool, str, Callable[[float], str]] = True,\n",
        "    animated: bool = False,\n",
        ") -> None:\n",
        "\n",
        "    if isinstance(predictions, torch.Tensor):\n",
        "        predictions = predictions.detach().cpu().numpy()\n",
        "    if isinstance(contacts, torch.Tensor):\n",
        "        contacts = contacts.detach().cpu().numpy()\n",
        "    if ax is None:\n",
        "        ax = plt.gca()\n",
        "\n",
        "    seqlen = contacts.shape[0]\n",
        "    relative_distance = np.add.outer(-np.arange(seqlen), np.arange(seqlen))\n",
        "    bottom_mask = relative_distance < 0\n",
        "    masked_image = np.ma.masked_where(bottom_mask, predictions)\n",
        "    invalid_mask = np.abs(np.add.outer(np.arange(seqlen), -np.arange(seqlen))) < 6\n",
        "    predictions = predictions.copy()\n",
        "    predictions[invalid_mask] = float(\"-inf\")\n",
        "\n",
        "    topl_val = np.sort(predictions.reshape(-1))[-seqlen]\n",
        "    pred_contacts = predictions >= topl_val\n",
        "    true_positives = contacts & pred_contacts & ~bottom_mask\n",
        "    false_positives = ~contacts & pred_contacts & ~bottom_mask\n",
        "    other_contacts = contacts & ~pred_contacts & ~bottom_mask\n",
        "\n",
        "    if isinstance(title, str):\n",
        "        title_text: Optional[str] = title\n",
        "    elif title:\n",
        "        long_range_pl = compute_precisions(predictions, contacts, minsep=24)[\n",
        "            \"P@L\"\n",
        "        ].item()\n",
        "        if callable(title):\n",
        "            title_text = title(long_range_pl)\n",
        "        else:\n",
        "            title_text = f\"Long Range P@L: {100 * long_range_pl:0.1f}\"\n",
        "    else:\n",
        "        title_text = None\n",
        "\n",
        "    img = ax.imshow(masked_image, cmap=cmap, animated=animated)\n",
        "    oc = ax.plot(*np.where(other_contacts), \"o\", c=\"grey\", ms=ms)[0]\n",
        "    fn = ax.plot(*np.where(false_positives), \"o\", c=\"r\", ms=ms)[0]\n",
        "    tp = ax.plot(*np.where(true_positives), \"o\", c=\"b\", ms=ms)[0]\n",
        "    ti = ax.set_title(title_text) if title_text is not None else None\n",
        "    # artists = ContactAndPredictionArtists(img, oc, fn, tp, ti)\n",
        "\n",
        "    ax.axis(\"square\")\n",
        "    ax.set_xlim([0, seqlen])\n",
        "    ax.set_ylim([0, seqlen])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TODO: Figure out how to analyze MSATransformer output in a way that makes sense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Read Data\n",
        "# This is where the data is actually read in\n",
        "import os\n",
        "\n",
        "pdbId0 = '1k0n' #@param {type:\"string\"}\n",
        "#@markdown - Specify the 1st PDB ID to compare\n",
        "pdbId1 = '1rk4' #@param {type:\"string\"}\n",
        "#@markdown - Specify the 2nd PDB ID to compare\n",
        "PDB_IDS = [pdbId0, pdbId1]\n",
        "\n",
        "structures = {\n",
        "    name.lower(): get_structure(PDBxFile.read(rcsb.fetch(name, \"cif\")))[0]\n",
        "    for name in PDB_IDS\n",
        "}\n",
        "\n",
        "contacts = {\n",
        "    name: contacts_from_pdb(structure, chain=\"A\")\n",
        "    for name, structure in structures.items()\n",
        "}\n",
        "\n",
        "msas = {\n",
        "        name: read_msa(f\"/content/MSATransformer_output/{name}\")\n",
        "    for name in os.listdir(\"/content/MSATransformer_output/\")\n",
        "}\n",
        "\n",
        "sequences = {\n",
        "    name: msa[0] for name, msa in msas.items()\n",
        "}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "6T7Pcz-poDFn"
      },
      "source": [
        "### Predict and Visualize via ESM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Qce87TjvbEDA",
        "outputId": "ed61a404-a59c-417e-b087-77d69a1e168c"
      },
      "outputs": [],
      "source": [
        "#@title ESM-2 pred\n",
        "esm2, esm2_alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
        "esm2 = esm2.eval().cuda()\n",
        "esm2_batch_converter = esm2_alphabet.get_batch_converter()\n",
        "esm2_predictions = {}\n",
        "esm2_results = []\n",
        "for name, inputs in sequences.items():\n",
        "    esm2_batch_labels, esm2_batch_strs, esm2_batch_tokens = esm2_batch_converter([inputs])\n",
        "    esm2_batch_tokens = esm2_batch_tokens.to(next(esm2.parameters()).device)\n",
        "    esm2_predictions[name] = esm2.predict_contacts(esm2_batch_tokens)[0].cpu()\n",
        "    metrics = {\"id\": name, \"model\": \"ESM-2 (Unsupervised)\"}\n",
        "    metrics.update(evaluate_prediction(esm2_predictions[name], contacts[name]))\n",
        "    esm2_results.append(metrics)\n",
        "esm2_results = pd.DataFrame(esm2_results)\n",
        "display(esm2_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "WnlwYZeUbgLO",
        "outputId": "3d3eb320-f12c-46c4-d5c5-4e6467408b54"
      },
      "outputs": [],
      "source": [
        "#@title ESM-2 Graph\n",
        "fig, axes = plt.subplots(figsize=(18, 6), ncols=len(PDB_IDS))\n",
        "for ax, name in zip(axes, PDB_IDS):\n",
        "    prediction = esm2_predictions[name]\n",
        "    target = contacts[name]\n",
        "    plot_contacts_and_predictions(\n",
        "        prediction, target, ax=ax, title = lambda prec: f\"{name}: Long Range P@L: {100 * prec:0.1f}\"\n",
        "    )\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IohE_rsToQAK"
      },
      "source": [
        "### Predict and Visualize via MSA Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "kIiH7a5olI_A"
      },
      "outputs": [],
      "source": [
        "#@title MSA Transformer pred\n",
        "msa_transformer, msa_transformer_alphabet = esm.pretrained.esm_msa1b_t12_100M_UR50S()\n",
        "msa_transformer = msa_transformer.eval().cuda()\n",
        "msa_transformer_batch_converter = msa_transformer_alphabet.get_batch_converter()\n",
        "msa_transformer_predictions = {}\n",
        "msa_transformer_results = []\n",
        "for name, inputs in msas.items():\n",
        "    inputs = greedy_select(inputs, num_seqs=128) # can change this to pass more/fewer sequences\n",
        "    msa_transformer_batch_labels, msa_transformer_batch_strs, msa_transformer_batch_tokens = msa_transformer_batch_converter([inputs])\n",
        "    msa_transformer_batch_tokens = msa_transformer_batch_tokens.to(next(msa_transformer.parameters()).device)\n",
        "    msa_transformer_predictions[name] = msa_transformer.predict_contacts(msa_transformer_batch_tokens)[0].cpu()\n",
        "    metrics = {\"id\": name, \"model\": \"MSA Transformer (Unsupervised)\"}\n",
        "    metrics.update(evaluate_prediction(msa_transformer_predictions[name], contacts[name]))\n",
        "    msa_transformer_results.append(metrics)\n",
        "msa_transformer_results = pd.DataFrame(msa_transformer_results)\n",
        "display(msa_transformer_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "6iPBer65nPRI",
        "outputId": "27ae06e6-153c-4010-9e78-04ce46bbbee7"
      },
      "outputs": [],
      "source": [
        "#@title MSA Transformer Graph\n",
        "fig, axes = plt.subplots(figsize=(18, 6), ncols=len(PDB_IDS))\n",
        "for ax, name in zip(axes, PDB_IDS):\n",
        "    prediction = msa_transformer_predictions[name]\n",
        "    target = contacts[name]\n",
        "    plot_contacts_and_predictions(\n",
        "        prediction, target, ax=ax, title = lambda prec: f\"{name}: Long Range P@L: {100 * prec:0.1f}\"\n",
        "    )\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "U0ukYqqzateL",
        "q1eZWXv1bxGl",
        "i7iXPaDKZ5vx",
        "rb4cDoG2ns91",
        "tV3WCbn6aXL7",
        "mqwybh2Tn_Ou",
        "lW5thQpSn0Rp",
        "cvYiSUg7n5rP",
        "WnZSlf1EoGys"
      ],
      "name": "esm_contact_prediction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
